{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbfbe89",
   "metadata": {},
   "source": [
    "# 端到端体验AIGC-从SageMaker到Web应用\n",
    "\n",
    "生成式AI技术正在迅速提高，现在可以简单地根据文本输入来生成文本和图像。 本次动手训练营将采用Stable Diffusion🧨模型。\n",
    "\n",
    "Stable Diffusion🧨是一种文本到图像模型，可让您创建逼真的AIGC应用程序。\n",
    "\n",
    "在本次动手训练营中，您将了解到:\n",
    " 1. Stable Diffusion模型生成图片的过程\n",
    " 2. 在Sagemaker Notebook Instance中运行该模型\n",
    " 3. 使用Sagemaker Notebook Instance部署模型并进行推理\n",
    " 4. 使用会话管理器登陆到推理机器（可选）\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d8464",
   "metadata": {},
   "source": [
    "## 1.准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55254b1a",
   "metadata": {},
   "source": [
    "### 1.1 安装及环境配置工作 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536af417",
   "metadata": {},
   "source": [
    "#### 检查环境版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66083a9",
   "metadata": {},
   "source": [
    "#### 安装Notebook运行模型所需的库文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo yum -y install pigz\n",
    "!pip install -U pip\n",
    "!pip install -U transformers==4.26.1 diffusers==0.13.1 ftfy accelerate\n",
    "!pip install -U torch==1.13.1+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -U sagemaker\n",
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa562670",
   "metadata": {},
   "source": [
    "### 1.2 下载模型文件\n",
    "\n",
    "#### 目前Stable Diffusion发布了Stable Diffusion V1和Stable Diffusion V2版本。\n",
    "\n",
    "起初的[Stable Diffusion V1](https://github.com/CompVis/stable-diffusion) 由 [CompVis](https://ommer-lab.com) 领导，改变了开源人工智能模型的性质，并在全球范围内催生了数百个其他模型和创新。它是所有软件中最快达到 10K Github star 的软件之一，在不到两个月的时间内飙升至 33K star。\n",
    "\n",
    "Stable Diffusion V1使用*降采样因子8*(downsampling-factor 8)自动编码器和860M UNet和 CLIP ViT-L/14文本编码器用于扩散模型。该模型在 256x256 图像上进行预训练，然后在 512x512 图像上进行微调。\n",
    "\n",
    "与最初的 V1 版本相比，[Stable Diffusion V2](https://github.com/Stability-AI/StableDiffusion) 提供了许多重大改进和特性，具体表现在：\n",
    "\n",
    "Stable Diffusion V2版本包含一个具有鲁棒性的文本生成图像模型，在全新的文本编码器 (OpenCLIP) 上训练而成，与早期的 V1 版本相比，文本 -> 图像模型大大提高了图像生成质量，可以生成默认分辨率为 512x512 像素和 768x768 像素的图像。\n",
    "\n",
    "- [Stable Diffusion Launch Announcement](https://stability.ai/blog/stable-diffusion-announcement)\n",
    "- [Stable Diffusion 2.0 Release](https://stability.ai/blog/stable-diffusion-v2-release)\n",
    "\n",
    "#### Stable Diffusion的开源模型文件存放在Hugging Face上。\n",
    "\n",
    "Hugging Face🤗 是一个 AI/ML 社区和平台，早期靠 Transformers 模型库和高质量社区受到关注。用户可以在 Hugging Face 上托管和共享 ML 模型、数据集，也可以构建、训练和部署模型。截至目前，Hugging Face 上共有 7.7 万个预训练模型，以 NLP 模型为主，目前 NLP 模型占比为 50%，2022 年初为 70%，这一比例未来会继续下降。Hugging Face 现在是 NLP 领域的 GitHub，未来希望成为整个 ML 领域的 GitHub，并逐渐向 ML Workflow 的其他环节渗透。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda39128",
   "metadata": {},
   "source": [
    "### 安装git lfs以克隆模型仓库 （git lfs支持大文件上传与下载）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0351bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo yum install -y amazon-linux-extras\n",
    "!sudo amazon-linux-extras install epel -y\n",
    "!sudo yum-config-manager --enable epel\n",
    "!sudo yum install git-lfs -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77e9b2",
   "metadata": {},
   "source": [
    "### 设定模型版本的环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8853697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Stable Diffusion model from HuggingFace\n",
    "\n",
    "#### Stable Diffusion V1\n",
    "SD_SPACE=\"runwayml/\"\n",
    "SD_MODEL = \"stable-diffusion-v1-5\"\n",
    "\n",
    "#### Stable Diffusion V2\n",
    "# SD_SPACE=\"stabilityai/\"\n",
    "# SD_MODEL = \"stable-diffusion-2-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3932cf",
   "metadata": {},
   "source": [
    "### 克隆模型仓库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated time to spend 3min(V1), 8min(V2)\n",
    "%cd ~/SageMaker\n",
    "!printf \"=======Current Path========%s\\n\"\n",
    "!rm -rf $SD_MODEL\n",
    "# !git lfs clone https://huggingface.co/$SD_SPACE$SD_MODEL -X \"*.safetensors\"\n",
    "!mkdir $SD_MODEL\n",
    "%cd $SD_MODEL\n",
    "!git init\n",
    "!git config core.sparseCheckout true\n",
    "!echo \"/*\" >> .git/info/sparse-checkout\n",
    "!echo \"!**/*.safetensors\" >> .git/info/sparse-checkout\n",
    "!git remote add -f master https://huggingface.co/$SD_SPACE$SD_MODEL\n",
    "!git pull master main\n",
    "%cd ~/SageMaker\n",
    "!printf \"=======Folder========%s\\n$(ls)\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe3b23",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.在Notebook中配置并使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd041ff9",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "from diffusers import StableDiffusionPipeline\n",
    "# Load stable diffusion\n",
    "pipe = StableDiffusionPipeline.from_pretrained(SD_MODEL, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84a5dc",
   "metadata": {},
   "source": [
    "### 使用GPU进行运算并设定参数\n",
    "\n",
    "为模型设定输入参数，可使用的部分参数如下：\n",
    "- prompt (`str` or `List[str]`):\n",
    "  - 引导图像生成的文本提示或文本列表\n",
    "- height (`int`, *optional*, 默认为 V1模型可支持到512像素，V2模型可支持到768像素):\n",
    "  - 生成图像的高度（以像素为单位）\n",
    "- width (`int`, *optional*,  默认为 V1模型可支持到512像素，V2模型可支持到768像素):\n",
    "  - 生成图像的宽度（以像素为单位）\n",
    "- num_inference_steps (`int`, *optional*, defaults to 50):\n",
    "  - 降噪步数。更多的去噪步骤通常会以较慢的推理为代价获得更高质量的图像\n",
    "- guidance_scale (`float`, *optional*, defaults to 7.5):\n",
    "  - 较高的指导比例会导致图像与提示密切相关，但会牺牲图像质量。 如果指定，它必须是一个浮点数。 guidance_scale<=1 被忽略。\n",
    "- negative_prompt (`str` or `List[str]`, *optional*):\n",
    "  - 不引导图像生成的文本或文本列表。不使用时忽略，必须与prompt类型一致（如果 guidance_scale 小于 1 则忽略）\n",
    "- num_images_per_prompt (`int`, *optional*, defaults to 1):\n",
    "  - 每个提示生成的图像数量\n",
    "  \n",
    "更多参数请参考：https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\n",
    "\n",
    "\n",
    "\n",
    "*GPU内存不够怎么办？*\n",
    "- *试一试分辨率小一点的图片*\n",
    "- *减少生成图片的数量*\n",
    "- *升级机型*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1874593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move Model to the GPU\n",
    "torch.cuda.empty_cache()\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# V1 Max-H:512,Max-W:512\n",
    "# V2 Max-H:768,Max-W:768\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "prompts =[\n",
    "    \"Eiffel tower landing on the Mars\",\n",
    "    \"a photograph of an astronaut riding a horse,van Gogh style\",\n",
    "]\n",
    "generated_images = pipe(\n",
    "    prompt=prompts,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_images_per_prompt=1\n",
    ").images  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
    "\n",
    "print(f\"Prompts: {prompts}\\n\")\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "for image in generated_images:\n",
    "    display(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c397444",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.部署模型至Sagemaker Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b7773",
   "metadata": {},
   "source": [
    "构建和训练模型后，您可以将模型部署至终端节点，以中获取预测推理结果。\n",
    "\n",
    "使用 SageMaker 托管服务部署模型有多种选择。 你可以使用 AWS 开发工具包（例如，Python 开发工具包 (Boto3)）、SageMaker Python 开发工具包、AWS CLI 以编程方式部署模型， 或者您可以使用 SageMaker 控制台以交互方式部署模型。\n",
    "\n",
    "使用 SageMaker 托管服务部署模型是一个三步过程，如果您使用 适用于 Python (Boto3)、AWS CLI 或 SageMaker 控制台的 AWS 开发工具包：\n",
    "    \n",
    "    1.在 SageMaker 中创建 SageMaker 模型。\n",
    "    2.为 HTTPS 端点创建端点配置。\n",
    "    3.创建 HTTPS 端点。\n",
    "    \n",
    "使用 SageMaker Python 开发工具包部署模型不需要您创建终端节点配置。 因此，这是一个两步过程：\n",
    "    \n",
    "    1.从创建模型对象 Model可以部署到 HTTPS 端点的类。\n",
    "    2.使用模型对象的预构建创建 HTTPS 端点 deploy()方法。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6154598f",
   "metadata": {},
   "source": [
    "### 编写初始化的Sagemaker代码用于部署推理终端节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14eeb63",
   "metadata": {},
   "source": [
    "### 创建自定义推理 inference.py 脚本\n",
    "\n",
    "要使用自定义推理脚本，您需要创建一个 inference.py 脚本。 \n",
    "在我们的示例中，我们将编写 model_fn 以正确加载我们的模型，并编写 predict_fn 以处理数据。\n",
    "\n",
    "更多方法，请参考部署HuggingFace模型到Sagemaker中：https://huggingface.co/docs/sagemaker/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4323cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./$SD_MODEL/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099831cb",
   "metadata": {},
   "source": [
    "#### 为模型创建所需依赖声明的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d35c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile ./$SD_MODEL/code/requirements.txt\n",
    "diffusers==0.13.1\n",
    "transformers==4.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e427ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./$SD_MODEL/code/inference.py\n",
    "import base64\n",
    "import torch\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load stable diffusion and move it to the GPU\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_dir, torch_dtype=torch.float16)\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "\n",
    "    # get prompt & parameters\n",
    "    prompt = data.pop(\"prompt\", \"\")\n",
    "    # set valid HP for stable diffusion\n",
    "    height = data.pop(\"height\", 512)\n",
    "    width = data.pop(\"width\", 512)\n",
    "    num_inference_steps = data.pop(\"num_inference_steps\", 50)\n",
    "    guidance_scale = data.pop(\"guidance_scale\", 7.5)\n",
    "    num_images_per_prompt = data.pop(\"num_images_per_prompt\", 1)\n",
    "    # run generation with parameters\n",
    "    generated_images = pipe(\n",
    "        prompt=prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "    )[\"images\"]\n",
    "\n",
    "    # create response\n",
    "    encoded_images = []\n",
    "    for image in generated_images:\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "    # create response\n",
    "    return {\"generated_images\": encoded_images}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4846889",
   "metadata": {},
   "source": [
    "#### 打包模型并上传至S3桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4509c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package model, Estimated time to spend 2min(V1),5min(V2)\n",
    "!echo $(date)\n",
    "\n",
    "!tar --exclude .git --use-compress-program=pigz -pcvf ./$SD_MODEL'.tar.gz' -C ./$SD_MODEL/ .\n",
    "\n",
    "!echo $(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "# upload model.tar.gz to s3, Estimated time to spend 30s(V1), 1min(V2)\n",
    "sd_model_uri=S3Uploader.upload(local_path=f\"{SD_MODEL}.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/stable-diffusion/models\")\n",
    "print(f\"=======S3 File Location========\\nmodel uploaded to:\\n{sd_model_uri}\")\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7de00",
   "metadata": {},
   "source": [
    "#### 使用HuggingFace将模型部署至SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init variables\n",
    "huggingface_model = {}\n",
    "predictor = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99931527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model[SD_MODEL] = HuggingFaceModel(\n",
    "    model_data=sd_model_uri, # path to your model and script\n",
    "    role=role, # iam role with permissions to create an Endpoint\n",
    "    transformers_version=\"4.17\", # transformers version used\n",
    "    pytorch_version=\"1.10\", # pytorch version used\n",
    "    py_version='py38', # python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the endpoint endpoint, Estimated time to spend 5min(V1), 8min(V2)\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "predictor[SD_MODEL] = huggingface_model[SD_MODEL].deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.2xlarge\",\n",
    "    endpoint_name=f\"{SD_MODEL}-endpoint\"\n",
    ")\n",
    "\n",
    "print(f\"\\n{datetime.datetime.now()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "608fad82",
   "metadata": {},
   "source": [
    "#### 清理Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce129465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor[SD_MODEL].delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f4442",
   "metadata": {},
   "source": [
    "#### 基于推理终端节点生成自定义图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804494ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "    base64_image = base64.b64decode(image_string)\n",
    "    buffer = BytesIO(base64_image)\n",
    "    return Image.open(buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run prediction\n",
    "response = predictor[SD_MODEL].predict(data={\n",
    "    \"prompt\": [\n",
    "        \"Eiffel tower landing on the Mars\",\n",
    "#         \"a photograph of an astronaut riding a horse\",\n",
    "    ],\n",
    "    \"height\" : 512,\n",
    "    \"width\" : 512,\n",
    "    \"num_images_per_prompt\":1\n",
    "  }\n",
    ")\n",
    "\n",
    "#decode images\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "\n",
    "#visualize generation\n",
    "for image in decoded_images:\n",
    "    display(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000692b",
   "metadata": {},
   "source": [
    "## 4. 更进一步的探索（可选）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16980b42",
   "metadata": {},
   "source": [
    "在本节中，您可学习到如何使用会话管理器连接到Inference Endpoint实例中并进行调试性的工作。\n",
    "\n",
    "本操作采用SageMaker SSH Helper，参考：https://github.com/aws-samples/sagemaker-ssh-helper\n",
    "\n",
    "SageMaker SSH Helper 是一个库，可帮助您安全地连接到 Amazon SageMaker 的训练作业、处理作业、实时推理端点和 SageMaker Studio 笔记本容器，以进行快速交互式实验、远程调试和高级故障排除。\n",
    "\n",
    "**首先您需要为SageMaker执行角色添加权限：**\n",
    "\n",
    "**请参考：https://github.com/aws-samples/sagemaker-ssh-helper/blob/main/IAM_SSM_Setup.md**\n",
    "\n",
    "**并启用高级实例层以使用托管实例（例如 SageMaker 托管容器）： Systems Manager > 队列管理器 > 账户管理 > 实例等级设置 > 修改账户设置 > 确认从标准层到高级层的更改。**\n",
    "\n",
    "完成以上步骤，您需要安装一些依赖文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-ssh-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58163b78",
   "metadata": {},
   "source": [
    "初始化SageMaker以及变量，并添加依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4419da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./$SD_MODEL/code/requirements.txt\n",
    "diffusers==0.13.1\n",
    "transformers==4.26.1\n",
    "sagemaker-ssh-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6c6b0",
   "metadata": {},
   "source": [
    "在推理代码中添加以下代码：\n",
    "```sh\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), \"lib\"))\n",
    "\n",
    "import sagemaker_ssh_helper\n",
    "sagemaker_ssh_helper.setup_and_start_ssh()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf761420",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./$SD_MODEL/code/inference.py\n",
    "import base64\n",
    "import torch\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), \"lib\"))\n",
    "\n",
    "import sagemaker_ssh_helper\n",
    "sagemaker_ssh_helper.setup_and_start_ssh()\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load stable diffusion and move it to the GPU\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_dir, torch_dtype=torch.float16)\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "\n",
    "    # get prompt & parameters\n",
    "    prompt = data.pop(\"prompt\", \"\")\n",
    "    # set valid HP for stable diffusion\n",
    "    height = data.pop(\"height\", 512)\n",
    "    width = data.pop(\"width\", 512)\n",
    "    num_inference_steps = data.pop(\"num_inference_steps\", 50)\n",
    "    guidance_scale = data.pop(\"guidance_scale\", 7.5)\n",
    "    num_images_per_prompt = data.pop(\"num_images_per_prompt\", 1)\n",
    "    # run generation with parameters\n",
    "    generated_images = pipe(\n",
    "        prompt=prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "    )[\"images\"]\n",
    "\n",
    "    # create response\n",
    "    encoded_images = []\n",
    "    for image in generated_images:\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "    # create response\n",
    "    return {\"generated_images\": encoded_images}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2e8a3",
   "metadata": {},
   "source": [
    "#### 打包模型文件并上传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package model, Estimated time to spend 2min(V1),5min(V2)\n",
    "!echo $(date)\n",
    "\n",
    "!mkdir ./$SD_MODEL/code/lib\n",
    "!tar --exclude .git --use-compress-program=pigz -pcvf ./$SD_MODEL'-enable-ssh.tar.gz' -C ./$SD_MODEL/ .\n",
    "\n",
    "!echo $(date)\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "# upload model.tar.gz to s3, Estimated time to spend 30s(V1), 1min(V2)\n",
    "sd_model_uri=S3Uploader.upload(local_path=f\"{SD_MODEL}-enable-ssh.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/stable-diffusion\")\n",
    "print(f\"=======S3 File Location========\\nmodel uploaded to:\\n{sd_model_uri}\")\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1829d",
   "metadata": {},
   "source": [
    "#### 生成模型文件并部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ea799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper  # <--NEW--\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker import image_uris\n",
    "\n",
    "image_uri = image_uris.retrieve(instance_type=\"ml.g4dn\",framework='huggingface',region=f\"{sess.boto_region_name}\",version='4.17.0',image_scope='inference',base_framework_version='pytorch1.10.2')\n",
    "print(image_uri)\n",
    "\n",
    "# Create the SageMaker model\n",
    "ssh_model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=sd_model_uri,\n",
    "    role=role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=f\"{SD_MODEL}-ssh-model\",\n",
    "    dependencies=[SSHModelWrapper.dependency_dir()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce33818",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_wrapper = SSHModelWrapper.create(ssh_model, connection_wait_time_seconds=0) \n",
    "\n",
    "ssh_predictor = ssh_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    endpoint_name=f\"{SD_MODEL}-ssh-endpoint\"\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac1f7b",
   "metadata": {},
   "source": [
    "#### 测试推理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6873fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data={\n",
    "    \"prompt\": [\n",
    "        \"Eiffel tower landing on the Mars\",\n",
    "        \"a photograph of an astronaut riding a horse\",\n",
    "    ],\n",
    "    \"height\" : 512,\n",
    "    \"width\" : 512,\n",
    "    \"num_images_per_prompt\":1\n",
    "  }\n",
    "\n",
    "encoded_payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "response = ssh_predictor.predict(encoded_payload,  {\n",
    "            \"ContentType\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        },\n",
    ")\n",
    "\n",
    "#decode images\n",
    "decoded_images = [decode_base64_image(image) for image in json.loads(response)[\"generated_images\"]]\n",
    "\n",
    "#visualize generation\n",
    "for image in decoded_images:\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a61768",
   "metadata": {},
   "source": [
    "#### 获取推理实例ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_ids = ssh_wrapper.get_instance_ids()\n",
    "print(f'To connect over SSM run: aws ssm start-session --target {instance_ids[0]} --region {sess.boto_region_name}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a8693",
   "metadata": {},
   "source": [
    "#### 有了实例 ID，您就可以使用命令行或 通过亚马逊云科技 Web 控制台连接到训练/推理容器：\n",
    "\n",
    "A. 使用命令行连接：\n",
    "\n",
    "1. 在本地计算机上，确保安装了最新的 AWS CLI v2 （v1 将不起作用），请参考文档 [AWS CLI 的文档](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) 。\n",
    "2. 验证正在运行`aws --version`，打印 aws-cli/2.x.x ...\n",
    "\n",
    "3. 安装 Session Manager CLI 插件 按照 [SSM 文档中的说明](https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html) 。\n",
    "\n",
    "4. 运行此命令（将目标值替换为您的 SageMaker 作业的实例 ID）。 例如：\n",
    "\n",
    "​\t`aws ssm start-session --target mi-0d8404fdeef955ca3`\n",
    "\n",
    "B. 使用 亚马逊云科技 Web 控制台控制台连接：\n",
    "\n",
    "1. 在 控制台中，导航到 Systems Manager > 队列管理器。\n",
    "\n",
    "2. 选择节点，然后选择节点操作 > 启动终端会话。\n",
    "\n",
    "连接到容器后，若您需要切换到 root 用户请使用 `sudo -i`命令。 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
